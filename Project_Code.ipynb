{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a0af6-b04e-430b-aa99-caf8dae379d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae786a-b48b-41ed-887c-7f466fd7f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('diabetes_prediction_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764b0c3-a6ca-47e0-be66-1f52877da329",
   "metadata": {},
   "source": [
    "## Exploration of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ac788-3583-4979-97f2-34450c854422",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca81b13-19a6-4c02-b618-91f1da87a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.info() #Displays the information of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c969d2-ce0a-47f5-88f3-02c7c3774280",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.describe() #Gives statistical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec56152-4f63-4219-9b8f-fea5052330ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.isnull().sum() #checks for missing/null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787570e5-c7a9-47a4-8590-600d7c060915",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.duplicated().sum() #checks for duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71198727-649a-4a5f-88f4-06dc859bf0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode categorical variables (gender, smoknig history)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "categorical_columns = ['gender', 'smoking_history']\n",
    "for column in categorical_columns:\n",
    "    diabetes_df[column] = LabelEncoder().fit_transform(diabetes_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec56f2e-478f-47db-aca7-7c8dacb20c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks for anomalies and outputs the number of each anomaly per category if there are anomalies.\n",
    "#\n",
    "# Parameters:\n",
    "# - Dataset,          type=pandas.dataframe\n",
    "# - Quantile list,    type=list of floats   (Optional, default=[0.25, 0.50, 0.75]) \n",
    "#\n",
    "# Returns:\n",
    "# - Anomaly presence, type=boolean\n",
    "\n",
    "def check_anomalies(dataset, quantile_list=[0.25, 0.50, 0.75]):\n",
    "    # The quantiles are loaded from the quantile list.\n",
    "    low = quantile_list[0]\n",
    "    mid = quantile_list[1]\n",
    "    top = quantile_list[2]\n",
    "    \n",
    "    # The function assumes that there are no anomalies in the dataset until proven otherwise.\n",
    "    anomaly_presence = False\n",
    "    \n",
    "    for category in dataset:\n",
    "        # Checks if the current category contains exclusively numerical data.\n",
    "        # If the first entry in a category is a string, then that category is skipped to prevent a value error.\n",
    "        try:\n",
    "            if (type(dataset[category][0]) is str):\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Calculating the quantiles.\n",
    "        Q1 = dataset[category].quantile(low)\n",
    "        Q2 = dataset[category].quantile(mid)\n",
    "        Q3 = dataset[category].quantile(top)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calculating the bounds.\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "        # Checking for anomalies.\n",
    "        anomalies = dataset[(dataset[category] < lower_bound) | (dataset[category] > upper_bound)]\n",
    "        if (anomalies.shape[0] > 1):\n",
    "            anomaly_presence = True\n",
    "            print(\"There are \" + str(anomalies.shape[0]) + \" \" + category + \" anomalies in this dataset.\")\n",
    "        elif (anomalies.shape[0] == 1):\n",
    "            anomaly_presence = True\n",
    "            print(\"There is \" + str(anomalies.shape[0]) + \" \" + category + \" anomaly in this dataset.\")\n",
    "    \n",
    "    # If there is no anomaly in the dataset, the user is informed of the lack of anomalies.\n",
    "    if (anomaly_presence == False):\n",
    "        print(\"There are no anomalies in the dataset.  Hooray!\")\n",
    "        \n",
    "    # The function returns whether it found anomalies.\n",
    "    return anomaly_presence\n",
    "        \n",
    "# The anomalies for the diabetes dataset are checked using the defeault settings.\n",
    "check_anomalies(diabetes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b0890-789c-4796-ab72-aa2721b091dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrxi\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = diabetes_df.corr()\n",
    "sb.heatmap(correlation_matrix, annot=True, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd86d83-eeec-480c-917c-c1e7e804b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display class imbalance\n",
    "\n",
    "#grab counts\n",
    "counts = diabetes_df[diabetes_df.columns[-1]].value_counts()\n",
    "\n",
    "# Plot the imbalance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sb.barplot(x=counts.index, y=counts.values)\n",
    "plt.title('Imbalance of Values in Dataset (Target) Column')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(ticks=[0, 1], labels=['No Diabetes', 'Has Diabetes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d00b9d-0796-4027-9f17-e0f8fe318a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the data using visualization TODO add more visualizations\n",
    "\n",
    "#Pairplot\n",
    "sb.pairplot(diabetes_df)\n",
    "plt.suptitle('Pairplot of Features Colored by Dataset', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc891e-8852-4cad-b522-a694bdc1c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histoplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "for column in diabetes_df.columns[:-1]:  # Exclude the target column\n",
    "    sb.histplot(diabetes_df[column], label=column)\n",
    "plt.title('Histogram of Numerical Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6f540-072e-4ad4-a7e9-0740c3a1f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sb.boxplot(data=diabetes_df.drop(columns=['diabetes']))\n",
    "plt.title('Boxplot of Numerical Features')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7a62d-0dfb-491c-8ab8-5e879cead717",
   "metadata": {},
   "source": [
    "## Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b254f16-4774-425d-ba33-fddf746615a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing values\n",
    "diabetes_df = diabetes_df.fillna(diabetes_df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fc640-4f37-43d0-93d4-92d684bd4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = diabetes_df.drop_duplicates(keep='first') # drops the duplicate entries in the data set\n",
    "\n",
    "diabetes_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes anomalies from a dataset given a list of categories to check.\n",
    "#\n",
    "# Parameters:\n",
    "# - Dataset,       type=pandas.dataframe\n",
    "# - Categories,    type=list of strings\n",
    "# - Quantile list, type=list of floats   (Optional, default=[0.25, 0.50, 0.75]) \n",
    "#\n",
    "# Returns:\n",
    "# - Dataset,    type=pandas.dataframe\n",
    "\n",
    "def remove_anomalies(dataset, categories, quantile_list=[0.25, 0.50, 0.75]):\n",
    "    # The quantiles are loaded from the quantile list.\n",
    "    low = quantile_list[0]\n",
    "    mid = quantile_list[1]\n",
    "    top = quantile_list[2]\n",
    "    \n",
    "    # An empty dataset is initialized with the categories of the dataset.\n",
    "    anomalies = pd.DataFrame(columns=categories)\n",
    "    \n",
    "    for category in categories:\n",
    "        # Checks if the current category contains exclusively numerical data.\n",
    "        # If the first entry in a category is a string, then that category is skipped to prevent a value error.\n",
    "        try:\n",
    "            if (type(dataset[category][0]) is str):\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Calculating the quantiles.\n",
    "        Q1 = dataset[category].quantile(0.25)\n",
    "        Q2 = dataset[category].quantile(0.50)\n",
    "        Q3 = dataset[category].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calculating the bounds.\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "        # Compiling the anomalies.\n",
    "        current_anomaly = dataset[(dataset[category] < lower_bound) | (dataset[category] > upper_bound)]\n",
    "        anomalies = pd.concat([anomalies, current_anomaly])\n",
    "    \n",
    "    # The anomalies are cleared of all duplicates.\n",
    "    anomalies = anomalies.drop_duplicates()\n",
    "    \n",
    "    # The anomalies are removed from the dataset and returned for further use.\n",
    "    dataset = dataset.drop(anomalies.index)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# This is an example on how to use the remove_anomalies function.  Note that this is commented out because I don't\n",
    "# want to remove so many entries that it lobotomizes that models.\n",
    "#\n",
    "# The line of code below will remove all BMI anomalies from the diabetes dataframe.  Even if you want to remove\n",
    "# anomalies from just one category, the category you want to remove must be in a list.\n",
    "#remove_anomalies(diabetes_df, [\"bmi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467eb517-36b9-427a-bce5-f2d2b914af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting target from data\n",
    "data = diabetes_df[diabetes_df.columns[:-1]]\n",
    "target = diabetes_df[diabetes_df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243b4b4-35d4-4007-b0d7-c4b6b7c90031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Initializes StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data \n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d6b59-0a80-4c8f-a0b6-8db857118582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance classes with SMOTE\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "x,y = sm.fit_resample(scaled_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82378d99-e1ac-4e71-8f5e-39f5704f34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2afc7e3-2611-4e1b-a46b-23b7f0c3faf3",
   "metadata": {},
   "source": [
    "## Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ee9e7-f442-4c1f-91fa-adc673ec3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "#Naives bayes\n",
    "#KNN\n",
    "#Random forest\n",
    "#Decision tree\n",
    "#Bagging\n",
    "#AdaBoost\n",
    "#XGBoost\n",
    "#Voting\n",
    "#SVM\n",
    "#Neural Network\n",
    "#Deep Neural Network\n",
    "\n",
    "#Top Models we will run\n",
    "#GridSearchCV\n",
    "#RFE feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f529804-35a9-461e-a084-80d82ca31d53",
   "metadata": {},
   "source": [
    "### Standalone Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae7ab3-e38e-4410-a4fb-e0239bcfe743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression - Vance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Logistic_regression_model = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "pred_log_reg = Logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea75982-e937-461b-9159-51c0552fb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes - Jesus\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "pred_nb = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b3cc2-ea94-4091-9746-5a19e995466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN - Joshua\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(weights='distance', algorithm='auto').fit(X_train, y_train)\n",
    "\n",
    "pred_knn = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7f36e-3d05-4b1c-becd-163369facffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest - Joshua\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "pred_rfc = random_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de0a12-37f9-42d4-bd1f-c4a3ff9a9819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - Jesus \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_model = LinearSVC(random_state=42, dual=False)  # `dual=False` is preferable for cases where n_samples > n_features.\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = svm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e1cfd-93e9-471b-8d8c-073353265eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree - Vance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train,y_train)\n",
    "\n",
    "pred_decision_tree = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab34a0-69ac-4c0f-ad82-d83a7996a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "#https://keras.io/examples/structured_data/structured_data_classification_with_feature_space/\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops, models, optimizers\n",
    "from keras.utils import FeatureSpace\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined and preprocessed\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "simple_NN = models.Sequential(\n",
    "    [\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # For binary classification\n",
    "    ]\n",
    ")\n",
    "\n",
    "simple_NN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "simple_NN.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "pred_simple_NN = simple_NN.predict(X_test)\n",
    "\n",
    "pred_simple_NN = (pred_simple_NN > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9e458-13c9-45c6-ac96-95fa31bfecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_NN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d21b3-fcf7-4c7d-ad4f-d86f365d5503",
   "metadata": {},
   "source": [
    "### Combination Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc7bfa-488a-4a1d-8898-61dc2709e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging - David Visbal Gomez\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_model = BaggingClassifier(random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "pred_bagging = bagging_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580a9f7-43b9-455c-a6d1-f536cdc9d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost - David Visbal Gomez\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_boost_model = AdaBoostClassifier(algorithm='SAMME', random_state=42)\n",
    "ada_boost_model.fit(X_train, y_train)\n",
    "\n",
    "pred_ada_boost = ada_boost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c5e8b-baa7-4847-8128-59c1d5e35738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBoost - Vance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gboost_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gboost_model.fit(X_train, y_train)\n",
    "\n",
    "pred_gradient_boost = gboost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c9bee-967f-4844-b91b-bd356df69d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost - Vance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost_model = XGBClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "pred_xgboost = xgboost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ebc9a-9be8-4cd5-99a5-77fd73e44618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting - David Visbal Gomez\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# The estimators for the voting model are taken from previous models.\n",
    "# To be specific: logistic regression, naive bayes, and decision trees are used for the voting model.\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"lr\", Logistic_regression_model), \n",
    "        (\"nb\", nb_model), \n",
    "        (\"knn\", knn_model),\n",
    "        (\"svm\", svm_model)], \n",
    "    voting=\"hard\",\n",
    ")\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "pred_voting = voting_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a5a94-ae59-4a8d-8748-2488e5270bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced Neural Network - Vance\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined and preprocessed\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "reduce_lr_callback =  keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5,                    \n",
    "    patience=2, \n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "deep_NN = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # For binary classification\n",
    "])\n",
    "\n",
    "deep_NN.compile(optimizer='Nadam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "deep_NN.fit(\n",
    "    X_train, y_train, \n",
    "    batch_size=32, \n",
    "    epochs=50, \n",
    "    validation_data=(X_test, y_test), \n",
    "    callbacks=[reduce_lr_callback, early_stopping_callback])\n",
    "\n",
    "deep_NN.evaluate(X_test, y_test)\n",
    "\n",
    "# Make predictions\n",
    "pred_deep_NN = deep_NN.predict(X_test)\n",
    "\n",
    "pred_deep_NN = (pred_deep_NN > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec34f05-5e89-4b40-aef3-1ceaca252741",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_NN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f999a9d-75a5-4998-92a8-3b5a21d3b0e9",
   "metadata": {},
   "source": [
    "## Comparing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1819402-c9b8-497b-b091-546b0b087474",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a1d96-7a4c-4ddb-98bd-3990a25849f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "def evaluate(y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    mtc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    results = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'AUC': auc,\n",
    "        #'Matthews Corr Coef': mtc,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def displayCM(y_pred):\n",
    "    # Generate matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Display confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Diabetes (1)', 'No Diabetes (0)'])\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix Tree')\n",
    "    plt.show()\n",
    "\n",
    "def displayResultsTable(modelResults):\n",
    "    df = pd.DataFrame(modelResults).T\n",
    "    print(df)\n",
    "\n",
    "def findTopModels(modelResults, metricName, top_n=5):\n",
    "    # Create a list of tuples with (model_name, metric_score)\n",
    "    scores = [(model_name, metrics[metricName]) for model_name, metrics in modelResults.items()]\n",
    "    \n",
    "    # Sort the list by metric score in descending order\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top_n models\n",
    "    top_models = sorted_scores[:top_n]\n",
    "    \n",
    "    return top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a2c94-b883-4853-90bc-576b4d01eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = evaluate(pred_log_reg)\n",
    "decision_tree = evaluate(pred_decision_tree)\n",
    "KNN = evaluate(pred_knn)\n",
    "random_forest = evaluate(pred_rfc)\n",
    "neural_network = evaluate(pred_simple_NN)\n",
    "deep_neural_network = evaluate(pred_deep_NN)\n",
    "svm = evaluate(pred_svm)\n",
    "naive_bayes = evaluate(pred_nb)\n",
    "\n",
    "gboost = evaluate(pred_gradient_boost)\n",
    "xgboost = evaluate(pred_xgboost)\n",
    "\n",
    "# David Visbal Gomez's Models' Results\n",
    "bagging = evaluate(pred_bagging)\n",
    "ada_boost = evaluate(pred_ada_boost)\n",
    "voting = evaluate(pred_voting)\n",
    "\n",
    "modelResults = {\n",
    "    'Logistic Regression': logistic_regression,\n",
    "    'Naive Bayes': naive_bayes,\n",
    "    'KNN': KNN,\n",
    "    'Random Forest': random_forest,\n",
    "    'Decision Tree': decision_tree,\n",
    "    'Bagging': bagging,\n",
    "    'AdaBoost': ada_boost,\n",
    "    'Gradient Boost': gboost,\n",
    "    'Extreme Gradient Boost': xgboost,\n",
    "    'Voting': voting,\n",
    "    'SVM': svm,\n",
    "    'Neural Network': neural_network,\n",
    "    'Deep Neural Network': deep_neural_network,\n",
    "}\n",
    "\n",
    "displayResultsTable(modelResults)\n",
    "\n",
    "top_f1_models = findTopModels(modelResults,'F1')\n",
    "print()\n",
    "print(f'The model with the highest F1 score is {top_f1_models[0][0]} with a score of {top_f1_models[0][1]:.4f}')\n",
    "print()\n",
    "print(\"Top 5 models based on F1 score:\")\n",
    "for model_name, score in top_f1_models:\n",
    "    print(f'{model_name}: {score:.4f}')\n",
    "\n",
    "top_acc_models = findTopModels(modelResults,'Accuracy')\n",
    "print()\n",
    "print(f'The model with the highest accuracy score is {top_acc_models[0][0]} with a score of {top_acc_models[0][1]:.4f}')\n",
    "print()\n",
    "print(\"Top 5 models based on Accuracy score:\")\n",
    "for model_name, score in top_acc_models:\n",
    "    print(f'{model_name}: {score:.4f}')\n",
    "\n",
    "top_AUC_models = findTopModels(modelResults,'AUC')\n",
    "print()\n",
    "print(f'The model with the highest AUC score is {top_AUC_models[0][0]} with a score of {top_AUC_models[0][1]:.4f}')\n",
    "print()\n",
    "print(\"Top 5 models based on AUC score:\")\n",
    "for model_name, score in top_AUC_models:\n",
    "    print(f'{model_name}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20735421-3bd9-4858-bd29-d23f1bf5656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizations\n",
    "df = pd.DataFrame(modelResults).T\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sb.heatmap(df, annot=True, cmap=\"coolwarm\", fmt=\".4f\")\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a004a-dacb-4f13-ae03-34b34e4e3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar', figsize=(8, 20), subplots=True, sharex=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74862708-aa18-4dfa-800b-91786ba71afd",
   "metadata": {},
   "source": [
    "## Feature Selection & GridSearchCV on the Top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6faacf-79e8-4ffb-8807-f5a7f586d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting number of features: 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c10f1-6a8e-4c03-9eea-4e9bf9d939a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection using top model Random Forest\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "random_forest_rfe = RFECV(random_forest_model, scoring='f1')\n",
    "random_forest_rfe.fit(X_train, y_train)\n",
    "\n",
    "X_train_selected = random_forest_rfe.transform(X_train)\n",
    "X_test_selected = random_forest_rfe.transform(X_test)\n",
    "\n",
    "print(\"Optimal number of features: %d\" % random_forest_rfe.n_features_)\n",
    "print(\"Selected features: %s\" % random_forest_rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad541a-42fc-4371-82ba-27abc62dbed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator=random_forest_model, param_grid=param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_rf.fit(X_train_selected, y_train)\n",
    "\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "print(\"Best parameters for Random Forest: \", best_params_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f271016-daa1-45a8-8d50-76a15da09e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_bagging = {\n",
    "    'n_estimators': [10, 50],\n",
    "    'max_samples': [0.5, 1.0],\n",
    "    'max_features': [0.5, 1.0],\n",
    "}\n",
    "\n",
    "grid_search_bagging = GridSearchCV(estimator=bagging_model, param_grid=param_grid_bagging, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_bagging.fit(X_train_selected, y_train)\n",
    "best_params_bagging = grid_search_bagging.best_params_\n",
    "best_bagging_model = grid_search_bagging.best_estimator_\n",
    "print(\"Best parameters for Bagging: \", best_params_bagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37934fa2-d54a-4bb8-af54-6ee4f811a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=knn_model, param_grid=param_grid_knn, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_knn.fit(X_train_selected, y_train)\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "best_knn_model = grid_search_knn.best_estimator_\n",
    "print(\"Best parameters for KNN: \", best_params_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b1e74-dda4-457f-a2ff-9af4009c4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model.fit(X_train_selected, y_train)\n",
    "best_bagging_model.fit(X_train_selected, y_train)\n",
    "best_knn_model.fit(X_train_selected, y_train)\n",
    "\n",
    "pred_rf_best = best_rf_model.predict(X_test_selected)\n",
    "pred_bagging_best = best_bagging_model.predict(X_test_selected)\n",
    "pred_knn_best = best_knn_model.predict(X_test_selected)\n",
    "\n",
    "random_forest2 = evaluate(pred_rf_best)\n",
    "bagging2 = evaluate(pred_bagging_best)\n",
    "KNN2 = evaluate(pred_knn_best)\n",
    "\n",
    "modelResults2 = {\n",
    "    'Random Forest': random_forest2,\n",
    "    'Bagging': bagging2,\n",
    "    'KNN': KNN2,\n",
    "}\n",
    "\n",
    "randomforest_data = {\n",
    "    'Random Forest': random_forest,\n",
    "    'Random Forest (2)': random_forest2, \n",
    "}\n",
    "\n",
    "bagging_data = {\n",
    "    'Bagging': bagging,\n",
    "    'Bagging (2)': bagging2,\n",
    "}\n",
    "\n",
    "KNN_data = {\n",
    "    'KNN': KNN,\n",
    "    'KNN (2)': KNN2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdcf6c6-1164-40e5-9d89-629e9a250650",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayResultsTable(modelResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160d9e3-422c-429b-a647-d4f9538ac450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizations\n",
    "df = pd.DataFrame(modelResults2).T\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sb.heatmap(df, annot=True, cmap=\"coolwarm\", fmt=\".4f\")\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc16e79-db21-405d-a4e6-fd5e93e83093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare changes\n",
    "df = pd.DataFrame(randomforest_data).T\n",
    "df.plot(kind='bar', figsize=(6, 5))\n",
    "plt.ylim(0.90, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535c397-ea20-4a46-acaa-5a8f02d6f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bagging_data).T\n",
    "df.plot(kind='bar', figsize=(6, 6))\n",
    "plt.ylim(0.94, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bcd621-bfd8-4af6-9e9f-0af95271701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(KNN_data).T\n",
    "df.plot(kind='bar', figsize=(6, 6))\n",
    "plt.ylim(0.94, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9f9ad-5ebf-40de-9463-2354cc452893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
