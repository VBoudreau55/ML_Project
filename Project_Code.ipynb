{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a0af6-b04e-430b-aa99-caf8dae379d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae786a-b48b-41ed-887c-7f466fd7f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('diabetes_prediction_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764b0c3-a6ca-47e0-be66-1f52877da329",
   "metadata": {},
   "source": [
    "## Exploration of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ac788-3583-4979-97f2-34450c854422",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca81b13-19a6-4c02-b618-91f1da87a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.info() #Displays the information of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c969d2-ce0a-47f5-88f3-02c7c3774280",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.describe() #Gives statistical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec56152-4f63-4219-9b8f-fea5052330ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.isnull().sum() #checks for missing/null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787570e5-c7a9-47a4-8590-600d7c060915",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.duplicated().sum() #checks for duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71198727-649a-4a5f-88f4-06dc859bf0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode categorical variables (gender, smoknig history)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "categorical_columns = ['gender', 'smoking_history']\n",
    "for column in categorical_columns:\n",
    "    diabetes_df[column] = LabelEncoder().fit_transform(diabetes_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec56f2e-478f-47db-aca7-7c8dacb20c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Find/show anomalies (we have to find which columns to investigate or investigate all of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b0890-789c-4796-ab72-aa2721b091dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrxi\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = diabetes_df.corr()\n",
    "sb.heatmap(correlation_matrix, annot=True, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd86d83-eeec-480c-917c-c1e7e804b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display class imbalance\n",
    "\n",
    "#grab counts\n",
    "counts = diabetes_df[diabetes_df.columns[-1]].value_counts()\n",
    "\n",
    "# Plot the imbalance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sb.barplot(x=counts.index, y=counts.values)\n",
    "plt.title('Imbalance of Values in Dataset (Target) Column')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(ticks=[0, 1], labels=['No Diabetes', 'Has Diabetes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d00b9d-0796-4027-9f17-e0f8fe318a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the data using visualization TODO add more visualizations\n",
    "\n",
    "#Pairplot\n",
    "sb.pairplot(diabetes_df)\n",
    "plt.suptitle('Pairplot of Features Colored by Dataset', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc891e-8852-4cad-b522-a694bdc1c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histoplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "for column in diabetes_df.columns[:-1]:  # Exclude the target column\n",
    "    sb.histplot(diabetes_df[column], label=column)\n",
    "plt.title('Histogram of Numerical Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6f540-072e-4ad4-a7e9-0740c3a1f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sb.boxplot(data=diabetes_df.drop(columns=['diabetes']))\n",
    "plt.title('Boxplot of Numerical Features')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7a62d-0dfb-491c-8ab8-5e879cead717",
   "metadata": {},
   "source": [
    "## Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fc640-4f37-43d0-93d4-92d684bd4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = diabetes_df.drop_duplicates(keep='first') # drops the duplicate entries in the data set\n",
    "\n",
    "diabetes_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613a2f2-02c5-4ed4-bd64-de2add6f63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks for anomalies and outputs the number of each anomaly per category if there are anomalies.\n",
    "#\n",
    "# Parameters:\n",
    "# - Dataset,          type=pandas.dataframe\n",
    "# - Quantile list,    type=list of floats   (Optional, default=[0.25, 0.50, 0.75]) \n",
    "#\n",
    "# Returns:\n",
    "# - Anomaly presence, type=boolean\n",
    "\n",
    "def check_anomalies(dataset, quantile_list=[0.25, 0.50, 0.75]):\n",
    "    # The quantiles are loaded from the quantile list.\n",
    "    low = quantile_list[0]\n",
    "    mid = quantile_list[1]\n",
    "    top = quantile_list[2]\n",
    "    \n",
    "    # The function assumes that there are no anomalies in the dataset until proven otherwise.\n",
    "    anomaly_presence = False\n",
    "    \n",
    "    for category in dataset:\n",
    "        # Checks if the current category contains exclusively numerical data.\n",
    "        # If the first entry in a category is a string, then that category is skipped to prevent a value error.\n",
    "        try:\n",
    "            if (type(dataset[category][0]) is str):\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Calculating the quantiles.\n",
    "        Q1 = dataset[category].quantile(low)\n",
    "        Q2 = dataset[category].quantile(mid)\n",
    "        Q3 = dataset[category].quantile(top)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calculating the bounds.\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "        # Checking for anomalies.\n",
    "        anomalies = dataset[(dataset[category] < lower_bound) | (dataset[category] > upper_bound)]\n",
    "        if (anomalies.shape[0] > 1):\n",
    "            anomaly_presence = True\n",
    "            print(\"There are \" + str(anomalies.shape[0]) + \" \" + category + \" anomalies in this dataset.\")\n",
    "        elif (anomalies.shape[0] == 1):\n",
    "            anomaly_presence = True\n",
    "            print(\"There is \" + str(anomalies.shape[0]) + \" \" + category + \" anomaly in this dataset.\")\n",
    "    \n",
    "    # If there is no anomaly in the dataset, the user is informed of the lack of anomalies.\n",
    "    if (anomaly_presence == False):\n",
    "        print(\"There are no anomalies in the dataset.  Hooray!\")\n",
    "        \n",
    "    # The function returns whether it found anomalies.\n",
    "    return anomaly_presence\n",
    "        \n",
    "# The anomalies for the diabetes dataset are checked using the defeault settings.\n",
    "check_anomalies(diabetes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes anomalies from a dataset given a list of categories to check.\n",
    "#\n",
    "# Parameters:\n",
    "# - Dataset,       type=pandas.dataframe\n",
    "# - Categories,    type=list of strings\n",
    "# - Quantile list, type=list of floats   (Optional, default=[0.25, 0.50, 0.75]) \n",
    "#\n",
    "# Returns:\n",
    "# - Dataset,    type=pandas.dataframe\n",
    "\n",
    "def remove_anomalies(dataset, categories, quantile_list=[0.25, 0.50, 0.75]):\n",
    "    # The quantiles are loaded from the quantile list.\n",
    "    low = quantile_list[0]\n",
    "    mid = quantile_list[1]\n",
    "    top = quantile_list[2]\n",
    "    \n",
    "    # An empty dataset is initialized with the categories of the dataset.\n",
    "    anomalies = pd.DataFrame(columns=categories)\n",
    "    \n",
    "    for category in categories:\n",
    "        # Checks if the current category contains exclusively numerical data.\n",
    "        # If the first entry in a category is a string, then that category is skipped to prevent a value error.\n",
    "        try:\n",
    "            if (type(dataset[category][0]) is str):\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Calculating the quantiles.\n",
    "        Q1 = dataset[category].quantile(0.25)\n",
    "        Q2 = dataset[category].quantile(0.50)\n",
    "        Q3 = dataset[category].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calculating the bounds.\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "        # Compiling the anomalies.\n",
    "        current_anomaly = dataset[(dataset[category] < lower_bound) | (dataset[category] > upper_bound)]\n",
    "        anomalies = pd.concat([anomalies, current_anomaly])\n",
    "    \n",
    "    # The anomalies are cleared of all duplicates.\n",
    "    anomalies = anomalies.drop_duplicates()\n",
    "    \n",
    "    # The anomalies are removed from the dataset and returned for further use.\n",
    "    dataset = dataset.drop(anomalies.index)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# This is an example on how to use the remove_anomalies function.  Note that this is commented out because I don't\n",
    "# want to remove so many entries that it lobotomizes that models.\n",
    "#\n",
    "# The line of code below will remove all BMI anomalies from the diabetes dataframe.  Even if you want to remove\n",
    "# anomalies from just one category, the category you want to remove must be in a list.\n",
    "#remove_anomalies(diabetes_df, [\"bmi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467eb517-36b9-427a-bce5-f2d2b914af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting target from data\n",
    "data = diabetes_df[diabetes_df.columns[:-1]]\n",
    "target = diabetes_df[diabetes_df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243b4b4-35d4-4007-b0d7-c4b6b7c90031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Initializes StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data \n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d6b59-0a80-4c8f-a0b6-8db857118582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance classes with SMOTE\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "x,y = sm.fit_resample(scaled_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82378d99-e1ac-4e71-8f5e-39f5704f34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2afc7e3-2611-4e1b-a46b-23b7f0c3faf3",
   "metadata": {},
   "source": [
    "## Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ee9e7-f442-4c1f-91fa-adc673ec3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "#Naives bayes\n",
    "#KNN\n",
    "#Random forest\n",
    "#Decision tree\n",
    "#Bagging\n",
    "#AdaBoost\n",
    "#XGBoost\n",
    "#Voting\n",
    "#SVM\n",
    "#Neural Network\n",
    "#Deep Neural Network\n",
    "\n",
    "#Top Models we will run\n",
    "#GridSearchCV\n",
    "#RFE feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f529804-35a9-461e-a084-80d82ca31d53",
   "metadata": {},
   "source": [
    "### Standalone Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae7ab3-e38e-4410-a4fb-e0239bcfe743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression - Vance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Logistic_regression_model = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "pred_log_reg = Logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea75982-e937-461b-9159-51c0552fb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes - Jesus\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "pred_nb = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b3cc2-ea94-4091-9746-5a19e995466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN - Joshua\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(weights='distance', algorithm='auto').fit(X_train, y_train)\n",
    "\n",
    "pred_knn = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7f36e-3d05-4b1c-becd-163369facffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest - Joshua\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Random_forest_model = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "pred_rfc = Random_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de0a12-37f9-42d4-bd1f-c4a3ff9a9819",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "#SVM - Jesus \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_model = LinearSVC(random_state=42, dual=False)  # `dual=False` is preferable for cases where n_samples > n_features.\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = svm_model.predict(X_test)\n"
   ]
>>>>>>> main
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e1cfd-93e9-471b-8d8c-073353265eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree - Vance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "decision_tree.fit(X_train,y_train)\n",
    "\n",
    "pred_decision_tree = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab34a0-69ac-4c0f-ad82-d83a7996a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "#https://keras.io/examples/structured_data/structured_data_classification_with_feature_space/\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops, models, optimizers\n",
    "from keras.utils import FeatureSpace\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined and preprocessed\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "simple_NN = models.Sequential(\n",
    "    [\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # For binary classification\n",
    "    ]\n",
    ")\n",
    "\n",
    "simple_NN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "simple_NN.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "pred_simple_NN = simple_NN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d21b3-fcf7-4c7d-ad4f-d86f365d5503",
   "metadata": {},
   "source": [
    "### Combination Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc7bfa-488a-4a1d-8898-61dc2709e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580a9f7-43b9-455c-a6d1-f536cdc9d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c5e8b-baa7-4847-8128-59c1d5e35738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ebc9a-9be8-4cd5-99a5-77fd73e44618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting - "
   ]
  },
  {
   "cell_type": "raw",
   "id": "166ea909-27bb-48a7-a1ce-b5a50c43080e",
   "metadata": {},
   "source": [
    "#Deep Neural Network - Vance\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined and preprocessed\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "deep_NN = models.Sequential(\n",
    "    [\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # For binary classification\n",
    "    ]\n",
    ")\n",
    "\n",
    "deep_NN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "deep_NN.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "deep_NN.evaluate(X_test, y_test)\n",
    "\n",
    "# Make predictions\n",
    "pred_deep_NN = deep_NN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f999a9d-75a5-4998-92a8-3b5a21d3b0e9",
   "metadata": {},
   "source": [
    "## Comparing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1819402-c9b8-497b-b091-546b0b087474",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a1d96-7a4c-4ddb-98bd-3990a25849f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "def evaluate(y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    mtc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    results = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'AUC': auc,\n",
    "        #'Matthews Corr Coef': mtc,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluateNN():\n",
    "    return None\n",
    "\n",
    "def displayCM(y_pred):\n",
    "    # Generate matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Display confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Diabetes (1)', 'No Diabetes (0)'])\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix Tree')\n",
    "    plt.show()\n",
    "\n",
    "def displayResultsTable(modelResults):\n",
    "    df = pd.DataFrame(modelResults).T\n",
    "    print(df)\n",
    "\n",
    "def findTopModel(modelResults, metricName):\n",
    "    #find top model based on F1\n",
    "    top_model = None\n",
    "    top_score = 0\n",
    "    for model_name, metrics in modelResults.items():\n",
    "        if metrics[metricName] > top_score:\n",
    "            top_score = metrics[metricName]\n",
    "            top_model = model_name\n",
    "    return top_model, top_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a2c94-b883-4853-90bc-576b4d01eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = evaluate(pred_log_reg)\n",
    "\n",
    "decision_tree = evaluate(pred_decision_tree)\n",
    "\n",
    "#neural_network = evaluate(pred_simple_NN)\n",
    "\n",
    "#deep_neural_network = evaluate(pred_deep_NN)\n",
    "\n",
    "svm = evaluate(pred_svm)\n",
    "naive_bayes = evaluate(pred_nb)\n",
    "\n",
    "\n",
    "modelResults = {\n",
    "    'Logistic Regression': logistic_regression,\n",
    "    'Decision Tree': decision_tree,\n",
    "    #'Neural Network': neural_network,\n",
    "    #'Deep Neural Network': deep_neural_network\n",
    "    'SVM': svm,\n",
    "    'Naive Bayes': naive_bayes\n",
    "}\n",
    "\n",
    "displayResultsTable(modelResults)\n",
    "\n",
    "top_f1_model, top_f1_score = findTopModel(modelResults,'F1')\n",
    "print()\n",
    "print(f'The model with the highest F1 score is {top_f1_model} with a score of {top_f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74862708-aa18-4dfa-800b-91786ba71afd",
   "metadata": {},
   "source": [
    "## Feature Selection & GridSearchCV on the Top Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c10f1-6a8e-4c03-9eea-4e9bf9d939a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad541a-42fc-4371-82ba-27abc62dbed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bffacec8-8df8-4e1f-b356-0d901902caf3",
   "metadata": {},
   "source": [
    "## Recomparing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668c951-2fca-46cc-ae61-0734de46c5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e0b5c-fea7-45b5-9869-497cff76aadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf5abb6-5452-4e5d-95c5-f9192ac71286",
   "metadata": {},
   "source": [
    "## Final Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f771b-6168-4a86-bb9a-882d71cfb431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
